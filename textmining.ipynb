{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of each ball "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re,nltk, textblob, string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe\n",
    "data=pd.read_csv(\"DSAT Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Match_ID</th>\n",
       "      <th>Over</th>\n",
       "      <th>Commentary</th>\n",
       "      <th>Over_Run_Total</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.040000e+11</td>\n",
       "      <td>49.6</td>\n",
       "      <td>and india reach 300. there has been a 300 in ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Run_Bw_Wickets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.040000e+11</td>\n",
       "      <td>49.5</td>\n",
       "      <td>slower ball, ashwin bunts this to leg for -99...</td>\n",
       "      <td>4</td>\n",
       "      <td>Run_Bw_Wickets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.040000e+11</td>\n",
       "      <td>49.4</td>\n",
       "      <td>full toss on off, he just slogs, gets a thick...</td>\n",
       "      <td>4</td>\n",
       "      <td>Run_Bw_Wickets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.040000e+11</td>\n",
       "      <td>49.3</td>\n",
       "      <td>that's the closest you'll get to a hat-trick ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.040000e+11</td>\n",
       "      <td>49.2</td>\n",
       "      <td>sohail is doing the sajda after bowling rahan...</td>\n",
       "      <td>4</td>\n",
       "      <td>Wicket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Match_ID  Over                                         Commentary  \\\n",
       "0   0  8.040000e+11  49.6   and india reach 300. there has been a 300 in ...   \n",
       "1   1  8.040000e+11  49.5   slower ball, ashwin bunts this to leg for -99...   \n",
       "2   2  8.040000e+11  49.4   full toss on off, he just slogs, gets a thick...   \n",
       "3   3  8.040000e+11  49.3   that's the closest you'll get to a hat-trick ...   \n",
       "4   4  8.040000e+11  49.2   sohail is doing the sajda after bowling rahan...   \n",
       "\n",
       "   Over_Run_Total          Target  \n",
       "0               4  Run_Bw_Wickets  \n",
       "1               4  Run_Bw_Wickets  \n",
       "2               4  Run_Bw_Wickets  \n",
       "3               4             Dot  \n",
       "4               4          Wicket  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the head and shape of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101634, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                0\n",
       "Match_ID          0\n",
       "Over              0\n",
       "Commentary        0\n",
       "Over_Run_Total    0\n",
       "Target            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking For outliers through Boxplots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c08002ccf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_box=data.drop(['ID','Match_ID','Target','Commentary'],axis=1)\n",
    "sns.boxplot(data=data_box,palette='coolwarm',orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since Total Runs in an over is not exceeding 36 and Over number is not exceeding 50, we can assume that there are no outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new column Over_number which tells us only the over number rather than the ball number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Over_number']=data['Over'].apply(lambda x:str(x)[0:2].rstrip('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Match_ID</th>\n",
       "      <th>Over</th>\n",
       "      <th>Commentary</th>\n",
       "      <th>Over_Run_Total</th>\n",
       "      <th>Target</th>\n",
       "      <th>Over_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.040000e+11</td>\n",
       "      <td>49.6</td>\n",
       "      <td>and india reach 300. there has been a 300 in ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Run_Bw_Wickets</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.040000e+11</td>\n",
       "      <td>49.5</td>\n",
       "      <td>slower ball, ashwin bunts this to leg for -99...</td>\n",
       "      <td>4</td>\n",
       "      <td>Run_Bw_Wickets</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Match_ID  Over                                         Commentary  \\\n",
       "0   0  8.040000e+11  49.6   and india reach 300. there has been a 300 in ...   \n",
       "1   1  8.040000e+11  49.5   slower ball, ashwin bunts this to leg for -99...   \n",
       "\n",
       "   Over_Run_Total          Target Over_number  \n",
       "0               4  Run_Bw_Wickets          49  \n",
       "1               4  Run_Bw_Wickets          49  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataframe with text column Commentary and ID for further anaylsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data[['Commentary','ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Lower casing the words and tokenizing them and then stemming them using Prter Stemmer.\n",
    "data_text ['Commentary'].dropna(inplace=True)\n",
    "data_text['Commentary'] = [entry.lower() for entry in data_text['Commentary']]\n",
    "\n",
    "# Replacing the string -999 from the commentary whichs looks like a typo\n",
    "data_text['Commentary'] =data_text['Commentary'].replace(to_replace =\"-999\", value = \"\", regex = True)\n",
    "data_text['Commentary'] =data_text['Commentary'].replace(to_replace =\",\", value = \"\", regex = True)\n",
    "\n",
    "data_text['Commentary']= [word_tokenize(entry) for entry in data_text['Commentary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = PorterStemmer()\n",
    "data_text['Commentary']=data_text['Commentary'].apply(lambda x: ' '.join([pst.stem(i) for i in x]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Commentary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and india reach 300. there ha been a 300 in ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>slower ball ashwin bunt thi to leg for after w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Commentary\n",
       "0  and india reach 300. there ha been a 300 in ev...\n",
       "1  slower ball ashwin bunt thi to leg for after w..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text[['Commentary']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new vectorized dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Creating a TF-IDF vector of text column Commentary\n",
    "vect= TfidfVectorizer(max_features=1000,max_df=0.95, min_df=2,ngram_range = (1,2),stop_words='english')\n",
    "data_text_vect = pd.DataFrame(vect.fit_transform(data_text['Commentary']).toarray()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating the original dataframe data and vectorized data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Match_ID</th>\n",
       "      <th>Over</th>\n",
       "      <th>Commentary</th>\n",
       "      <th>Over_Run_Total</th>\n",
       "      <th>Target</th>\n",
       "      <th>Over_number</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.040000e+11</td>\n",
       "      <td>49.6</td>\n",
       "      <td>and india reach 300. there has been a 300 in ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Run_Bw_Wickets</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.040000e+11</td>\n",
       "      <td>49.5</td>\n",
       "      <td>slower ball, ashwin bunts this to leg for -99...</td>\n",
       "      <td>4</td>\n",
       "      <td>Run_Bw_Wickets</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Match_ID  Over                                         Commentary  \\\n",
       "0   0  8.040000e+11  49.6   and india reach 300. there has been a 300 in ...   \n",
       "1   1  8.040000e+11  49.5   slower ball, ashwin bunts this to leg for -99...   \n",
       "\n",
       "   Over_Run_Total          Target Over_number    0    1    2  ...  990  991  \\\n",
       "0               4  Run_Bw_Wickets          49  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1               4  Run_Bw_Wickets          49  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "   992  993  994  995  996  997  998  999  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[2 rows x 1007 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect= TfidfVectorizer(max_features=1000,max_df=0.95, min_df=2,ngram_range = (1,2),stop_words='english')\n",
    "data_text_vect = pd.DataFrame(vect.fit_transform(data_text['Commentary']).toarray()) \n",
    "train=pd.concat([data,data_text_vect],axis=1)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating the Target variable by encoding it and storing it in a different dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target\n",
       "0       2\n",
       "1       2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['Target']= label_encoder.fit_transform(data['Target']) \n",
    "\n",
    "#creating a new target dataframe\n",
    "target=data[['Target']]\n",
    "target.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping columns from training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Target','Commentary','ID','Match_ID','Over'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Over_Run_Total</th>\n",
       "      <th>Over_number</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Over_Run_Total Over_number    0    1    2    3    4    5    6    7  ...  \\\n",
       "0               4          49  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1               4          49  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "   990  991  992  993  994  995  996  997  998  999  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[2 rows x 1002 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into Test and Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(train,target,test_size=0.3,random_state=216)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running different models using training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR model Accuracy Score -> 79.17574462701882 \n",
      "LR model Accuracy Score -> 78.15420943885081 \n",
      "KNN model Accuracy Score -> 72.7267615928482 \n",
      "KNN model Accuracy Score -> 59.24043160276803 \n",
      "CART model Accuracy Score -> 99.96485950831425 \n",
      "CART model Accuracy Score -> 68.05286805942737 \n",
      "RNDF model Accuracy Score -> 98.87690988572312 \n",
      "RNDF model Accuracy Score -> 74.08087632416122 \n",
      "NB model Accuracy Score -> 65.68320143935455 \n",
      "NB model Accuracy Score -> 65.12085533436095 \n",
      "Wall time: 18min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(train,target,test_size=0.3,random_state=216)\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('RNDF', RandomForestClassifier()))\n",
    "models.append(('NB', naive_bayes.MultinomialNB()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    model.fit(Train_X,Train_Y)\n",
    "    predictions_NB = model.predict(Train_X)\n",
    "    print(\"{} model Accuracy Score -> {} \" .format(name,accuracy_score(predictions_NB, Train_Y)*100))\n",
    "    predictions_NB = model.predict(Test_X)\n",
    "    # Use accuracy_score function to get the accuracy\n",
    "    print(\"{} model Accuracy Score -> {} \" .format(name,accuracy_score(predictions_NB, Test_Y)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR model Accuracy Score -> 79.56774130071167 \n",
      "KNN model Accuracy Score -> 59.68318520219081 \n",
      "CART model Accuracy Score -> 69.27290020005903 \n",
      "RNDF model Accuracy Score -> 75.36322193434128 \n",
      "NB model Accuracy Score -> 66.15394706634746 \n",
      "Wall time: 8min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(train,target,test_size=0.3,random_state=216)\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('RNDF', RandomForestClassifier()))\n",
    "models.append(('NB', naive_bayes.MultinomialNB()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    model.fit(Train_X,Train_Y)\n",
    "    predictions_NB = model.predict(Test_X)\n",
    "    # Use accuracy_score function to get the accuracy\n",
    "    print(\"{} model Accuracy Score -> {} \" .format(name,accuracy_score(predictions_NB, Test_Y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  0.7233281952051425\n",
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Fit a AdaBoost model, \" compared to \"Logistic Regression, accuracy is down by 5%\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(train,target,test_size=0.3,random_state=216)\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf.fit(Train_X,Train_Y)\n",
    "y_pred = clf.predict(Test_X)\n",
    "print(\"Accuracy Score : \",accuracy_score(Test_Y, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  76.08146666229379\n",
      "Wall time: 30min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Fit a Gradient Boosting model, \" compared to \"Logistic Regression, accuracy is down by 3%\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(train,target,test_size=0.3,random_state=216)\n",
    "clf = GradientBoostingClassifier(n_estimators=100)\n",
    "clf.fit(Train_X,Train_Y)\n",
    "y_pred = clf.predict(Test_X)\n",
    "print(\"Accuracy Score : \",accuracy_score(Test_Y, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model classifies the data better than any other model with an accuracy of 79.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  79.56774130071167\n",
      "Confusion Matrix :\n",
      "[[ 2356   252   977    20]\n",
      " [  132 11133  1401    59]\n",
      " [  460  2263 10201    80]\n",
      " [   91   295   200   571]]\n",
      "Classification Report :\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.65      0.71      3605\n",
      "          1       0.80      0.87      0.83     12725\n",
      "          2       0.80      0.78      0.79     13004\n",
      "          3       0.78      0.49      0.61      1157\n",
      "\n",
      "avg / total       0.80      0.80      0.79     30491\n",
      "\n",
      "Wall time: 52.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fitting the Logistic Regression Model again to print of classification report. \n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(train,target,test_size=0.3,random_state=216)\n",
    "clf = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "clf.fit(Train_X,Train_Y)\n",
    "y_pred = clf.predict(Test_X)\n",
    "print(\"Accuracy Score : \",accuracy_score(Test_Y, y_pred)*100)\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(Test_Y, y_pred))\n",
    "print(\"Classification Report :\")\n",
    "print(classification_report(Test_Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1- score of the model is also pretty good which is a good indicator that the modeling is good at classifying even if our data was uneven."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
